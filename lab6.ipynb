{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9f7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Conv2D, MaxPooling2D, BatchNormalization, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7e3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859f3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_classes():\n",
    "    persons = os.listdir('data')\n",
    "    num_classes = len(persons)\n",
    "    return num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "004a6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(target_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    persons = os.listdir('data')\n",
    "    num_classes = len(persons)\n",
    "\n",
    "    for person_index, person in enumerate(persons):\n",
    "        folder_path = os.path.join('data', person)\n",
    "        person_images = load_images_from_folder(folder_path)\n",
    "        resized_images = [cv2.resize(img, target_size) for img in person_images]\n",
    "        images.extend(resized_images)\n",
    "        labels.extend([person_index] * len(resized_images))\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66560827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/facenet_keras.h5')\n",
    "model.load_weights('model/facenet_keras_weights.h5')\n",
    "model.layers.pop()\n",
    "last_layer_output = model.layers[-1].output\n",
    "num_classes = get_num_classes()\n",
    "output_layer = Dense(num_classes, activation='softmax')(last_layer_output)\n",
    "model = Model(inputs=model.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a1c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (160, 160)\n",
    "images, labels, num_classes = create_training_data(target_size)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "x_train = x_train / 255.0\n",
    "x_val = x_val / 255.0\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "datagen_train = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "datagen_train.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a1ba1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9656 - accuracy: 0.5294\n",
      "Epoch 1: val_accuracy improved from -inf to 0.40000, saving model to model\\facenet_retrained.h5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.9656 - accuracy: 0.5294 - val_loss: 1.0999 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.8824\n",
      "Epoch 2: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1878 - accuracy: 0.8824 - val_loss: 0.9422 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 3: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 4: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 5: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 6: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9694 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.8815 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 8: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7535 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 9: val_accuracy did not improve from 0.40000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6321 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 10: val_accuracy improved from 0.40000 to 0.80000, saving model to model\\facenet_retrained.h5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.8000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 11: val_accuracy did not improve from 0.80000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.8000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.4788e-04 - accuracy: 1.0000\n",
      "Epoch 12: val_accuracy did not improve from 0.80000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.4788e-04 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3479e-04 - accuracy: 1.0000\n",
      "Epoch 13: val_accuracy improved from 0.80000 to 1.00000, saving model to model\\facenet_retrained.h5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4.3479e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0564e-04 - accuracy: 1.0000\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.0564e-04 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.8000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5249e-04 - accuracy: 1.0000\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.5249e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.8000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.8179e-04 - accuracy: 1.0000\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8179e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4817e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4817e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0154e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0154e-04 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.8000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0310e-04 - accuracy: 1.0000\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0310e-04 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.1327e-05 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 9.1327e-05 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6153e-05 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.6153e-05 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1968e-05 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.1968e-05 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9074e-05 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 8.9074e-05 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.8000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8148e-05 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.8148e-05 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.8000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6196e-05 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.6196e-05 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9522e-05 - accuracy: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6.9522e-05 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.8000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7084e-05 - accuracy: 1.0000\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5.7084e-05 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.8000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6893e-05 - accuracy: 1.0000\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.6893e-05 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.8000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.5955e-05 - accuracy: 1.0000\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.5955e-05 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.8000\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 6.2658e-05 - accuracy: 1.0000\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 6.2658e-05 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model/facenet_retrained.h5', monitor='val_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39081a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.25548774003982544\n",
      "Test Accuracy: 0.9545454382896423\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels, _ = create_training_data(target_size)\n",
    "test_images = test_images / 255.0\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "model.load_weights('model/facenet_retrained.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fddf9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Ilya\n"
     ]
    }
   ],
   "source": [
    "image_path = 'test/test_1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (160, 160))\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image / 255.0\n",
    "predictions = model.predict(image)\n",
    "persons = os.listdir('data')\n",
    "predicted_person_index = np.argmax(predictions[0])\n",
    "predicted_person = persons[predicted_person_index]\n",
    "print(predicted_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c59b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "Ksyusha\n"
     ]
    }
   ],
   "source": [
    "image_path = 'test/test_2.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (160, 160))\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image / 255.0\n",
    "predictions = model.predict(image)\n",
    "persons = os.listdir('data')\n",
    "predicted_person_index = np.argmax(predictions[0])\n",
    "predicted_person = persons[predicted_person_index]\n",
    "print(predicted_person)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
